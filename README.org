#+title: Terrain Model Processing with Machine Learning

A fork of [[https://github.com/daa233/generative-inpainting-pytorch][this]] PyTorch implementation of the network described in the paper [[https://arxiv.org/abs/1801.07892][Generative Image Inpainting with Contextual Attention]].
This fork allows for the training of the network on all DEM filetypes (GeoTiff, NASA PDS3/4) supported by [[https://gdal.org/][GDAL]].
The checkpoint images from this training are saved using the Matplotlib terrain colormap to allow for better visualisation.

* Requirements
/Known working versions/

 - Python3 3.10
 - PyTorch 1.13
 - Torchvision 0.14
 - Numpy 1.24
 - GDAL 3.6
 - Matplotlib 3.6

* Train the model
Edit config in train.py
 - ~dataset~ should be the path to a folder containing _one or more_ DEM files, not to the file itself.
 - Each DEM is tiled into tiles of size specified by the user and then loaded into memory.

#+begin_src bash
python train.py
#+end_src

Checkpoint images and models will be saved to the =out= dir, which can be changed in config.

* Test trained model
The file =test.org= can be used to load a pre-trained model and generate GeoTiffs from it.
The file can be run using [[https://orgmode.org/worg/org-contrib/babel/][org-babel]] with the [[https://www.gnu.org/software/emacs/][Emacs]] editor, requiring the [[https://github.com/nnicandro/emacs-jupyter][emacs-jupyter]] plugin, however all of the code would run the exact same in a [[https://jupyter.org/][Jupyter]] notebook.
This was chosen over a normal python script as a lot of the tiled sections from lunar DEMs can be quite boring and so this allows the user to manually select tiles with interesting features to infill.

* Training Results

Training over [[https://wms.lroc.asu.edu/lroc/rdr_product_select][high-resolution NAC DTMs]]  with a third saved for testing.
The network was trained on a subset of the data on a local GPU with a batch size of 12 to allow for more accurate initial training.
For the remaining 106 epochs the network was trained on an Nvidia A100 80GB with a batch size of 64, when the generator wasserstein loss reached -200,000.

The network was trained with masks in the shape of a square to simulate smaller naturally occurring no-data voids such as craters, and splits down the entire image to simulate a DEM joining task.

** Training Checkpoints
Checkpoint images are saved in a grid where:
 - The top is the masked image
 - The middle is the infilling result
 - The bottom is the ground truth

#+html: <h3 align="center">Epoch 158</h3>
[[file:examples/158_dem.png]]

#+html: <h3 align="center">Epoch 163</h3>
[[file:examples/163_dem.png]]

** Testing Examples

*** Square Voids

#+html: <h3 align="center">Infilling Process</h3>
[[file:examples/50_fig_square.png]]


#+html: <h3 align="center">3D Render</h3>
[[file:examples/50_square.png]]

*** Split Voids

#+html: <h3 align="center">Infilling Process</h3>
[[file:examples/5_fig.png]]


#+html: <h3 align="center">3D Render</h3>
[[file:examples/5_split.png]]
