#+title: Terrain Model Processing with Machine Learning

A fork of [[https://github.com/daa233/generative-inpainting-pytorch][this]] PyTorch implementation of the network described in the paper [[https://arxiv.org/abs/1801.07892][Generative Image Inpainting with Contextual Attention]].
This fork allows for the training of the network on all DEM filetypes (GeoTiff, NASA PDS3/4) supported by [[https://gdal.org/][GDAL]].
The checkpoint images from this training are saved using the Matplotlib terrain colormap to allow for better visualisation.

* Requirements
/Known working versions/

 - Python3 3.10
 - PyTorch 1.13
 - Torchvision 0.14
 - Numpy 1.24
 - GDAL 3.6
 - Matplotlib 3.6

* Train the model
Edit config in train.py
 - ~dataset~ should be the path to a folder containing _one or more_ DEM files, not to the file itself.
 - Each DEM is tiled into tiles of size specified by the user and then loaded into memory.

#+begin_src bash
python train.py
#+end_src

Checkpoint images and models will be saved to the =out= dir, which can be changed in config.

* Test trained model
The org file =test.org= can be used to test a trained model using RMSE, MAE and SSIM.
The file can be run using [[https://orgmode.org/worg/org-contrib/babel/][org-babel]] with the [[https://www.gnu.org/software/emacs/][Emacs]] editor, requiring the [[https://github.com/nnicandro/emacs-jupyter][emacs-jupyter]] plugin, however all of the code would run the exact same in a [[https://jupyter.org/][Jupyter]] notebook.
Org files can be converted into Jupiter notebooks using [[https://pandoc.org/][Pandoc]].

* Use trained model
The org file =infill.org= can be used to load a pre-trained model and infill DEMs with it.

* Training Results
Trained over 64 [[https://wms.lroc.asu.edu/lroc/rdr_product_select][high-resolution NAC DTMs]] with another 32 saved for testing.
The network was trained on a local GPU with a batch size of 12 to allow for more accurate initial training.
For the remaining epochs the network was trained on an Nvidia A100 80GB with a batch size of 64 until converged.

The network was trained with masks in the shape of a square to simulate smaller naturally occurring no-data voids such as craters, and splits down the entire image to simulate a DEM joining task.

** Training Checkpoints
Checkpoint images are saved in a grid where:
 - The top is the masked image
 - The middle is the infilling result
 - The bottom is the ground truth

#+html: <h3 align="center">Box Mask</h3>
[[file:examples/box_training.png]]

#+html: <h3 align="center">Split Mask</h3>
[[file:examples/split_training.png]]

** Infill Example

#+html: <h3 align="center">Void</h3>
[[file:examples/400_void.png]]

#+html: <h3 align="center">Infilled</h3>
[[file:examples/400.png]]
