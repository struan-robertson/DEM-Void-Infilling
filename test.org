#+title: Test
#+property: header-args :session test

* Imports

#+begin_src jupyter-python
import matplotlib.pyplot as plt
import numpy as np
import math
import toml
import os
import time
from osgeo import gdal
import torch
from tqdm import tqdm
import torch.nn.functional as F

from networks import Generator as GSlope
from networks_no_slope import Generator as GNoSlope
from tools import random_bbox, mask_image
#+end_src

#+RESULTS:

* Settings

#+begin_src jupyter-python
with open('config.toml', 'r') as file:
    config = toml.load(file)

# Test specific settings
config['cuda'] = True
config['dataset_name'] = "../Test Data"
config['seed'] = 1433
#+end_src

#+RESULTS:

* Tile Dataset

#+begin_src jupyter-python
def normalise(arr):
    normalized = (arr - arr.min()) / (arr.max() - arr.min())


    normalized = 2*normalized - 1

    return normalized

def partial_norm(arr):
    normalized = (arr - arr.min()) / (arr.max() - arr.min())

    normalized = normalized - 1

    return normalized

#+end_src

#+RESULTS:

#+begin_src jupyter-python
def tile(dataset, kernel_size):

    start_time = time.time()
    vectorized_normalise = np.vectorize(normalise, signature="(n,m)->(n,m)")

    # Slightly strange way to do it but used for counting files first
    files = os.listdir(dataset)
    n_files = len(files)

    dems = []
    min_max = []

    for i, file in enumerate(files):
        path = os.path.join(dataset, file)

        pds = gdal.Open(path)
        geot = pds.GetGeoTransform()
        crs = pds.GetProjection()

        image = np.array(pds.ReadAsArray())

        img_height, img_width = image.shape
        tile_height, tile_width = kernel_size

        # If cant divide perfectly
        if img_height % tile_height != 0 or img_width % tile_width != 0:
            new_height = img_height - (img_height % tile_height)
            new_width = img_width - (img_width % tile_width)

            image = image[:new_height, :new_width]

        tiles_high = img_height // tile_height
        tiles_wide = img_width // tile_width

        tiled_array = image.reshape(tiles_high, tile_height, tiles_wide, tile_width)

        tiled_array = tiled_array.swapaxes(1, 2)

        tiled_array = tiled_array.reshape(
            tiles_high * tiles_wide, tile_height, tile_width
        )

        for tile in tiled_array:
            min_max.append((tile.min(), tile.max()))

        tiled_array = vectorized_normalise(tiled_array)

        # Slope
        cellsize = geot[1]
        px, py = np.gradient(tiled_array, cellsize, axis=(1, 2))
        slope = np.arctan(np.sqrt(px**2 + py**2))
        slope = vectorized_normalise(slope)

        # RDLS
        # windowed = sliding_window_view(tiled_array, (3,3), axis=(1,2)) # type: ignore
        # rdls = np.ptp(windowed, axis=(3,4))
        # rdls = np.pad(rdls, ((0,0), (1,1), (1,1)), mode='constant', constant_values=0)
        # rdls = vectorized_normalise(rdls)

        all = np.stack((tiled_array, slope), axis=3)

        # tiled_array = np.expand_dims(tiled_array, axis=3)
        all = np.transpose(all, (0, 3, 1, 2))

        file = os.path.basename(path)

        # V much all over the place since different DEMS take v different amounts of time to process, however gives a rough idea of where the proceesing is at
        print(f"loaded DEM {file}: {i}/{n_files}")

        i += 1

        dems.append(all)


    full = np.concatenate((*dems,))

    dems = None

    full = torch.from_numpy(full)

    end_time = int(time.time() - start_time)

    print(f"Loaded all DEMs in {end_time} seconds")

    return full, min_max, crs, geot

#+end_src

#+RESULTS:

* Image Transformations
#+begin_src jupyter-python

# Return data from -1<->1 normalisation to original state

def denormalize(tensor, max, min):
    arr = tensor.cpu().detach().numpy()

    arr = np.squeeze(arr)

    # arr = np.transpose(arr, (1,2,0))

    arr = (arr * 0.5) + 0.5
    arr = (arr * (max - min)) + min

    return arr

# Return data from -1<->1 normalisation to 0<->1 normalisation
# Used as poisson blending requires the DEM data to be 0<->1 but the inpainted DEM is returened -1<->1
def partial_dn(tensor):

    # arr = tensor.cpu().detach().numpy()

    # arr = np.squeeze(arr)
    # arr = np.transpose(arr, (1,2,0))

    tensor = (tensor * 0.5) + 0.5

    return tensor

#+end_src

#+RESULTS:

* Load Data

#+begin_src jupyter-python
tiled, min_max, crs, geo_transform = tile(config["dataset_name"], (256, 256))

tiled.shape
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
loaded DEM NAC_DTM_RUMKERDOM10.TIF: 0/32
loaded DEM NAC_DTM_LUNA20.TIF: 1/32
loaded DEM NAC_DTM_NRTHCRTRIII.TIF: 2/32
loaded DEM NAC_DTM_KARRER3.TIF: 3/32
loaded DEM NAC_DTM_HSCARP2.TIF: 4/32
loaded DEM NAC_DTM_MESSIER3.TIF: 5/32
loaded DEM NAC_DTM_TYCHOPK06.TIF: 6/32
loaded DEM NAC_DTM_HPONDS1.TIF: 7/32
loaded DEM NAC_DTM_LACUSMORT02.TIF: 8/32
loaded DEM NAC_DTM_ARAGO2_2.TIF: 9/32
loaded DEM NAC_DTM_BARRINGERZ1.TIF: 10/32
loaded DEM NAC_DTM_SPARIM4.TIF: 11/32
loaded DEM NAC_DTM_NASSAU01.TIF: 12/32
loaded DEM NAC_DTM_HPONDS15.TIF: 13/32
loaded DEM NAC_DTM_NRTHCRTRI2.TIF: 14/32
loaded DEM NAC_DTM_ORIENTALE1.TIF: 15/32
loaded DEM NAC_DTM_MRINGENII6.TIF: 16/32
loaded DEM NAC_DTM_ATLAS2.TIF: 17/32
loaded DEM NAC_DTM_VSCHROTERI2.TIF: 18/32
loaded DEM NAC_DTM_RUMKERDOME.TIF: 19/32
loaded DEM NAC_DTM_THEOPHILUS3.TIF: 20/32
loaded DEM NAC_DTM_VINGHIRAMI.TIF: 21/32
loaded DEM NAC_DTM_MARIUSPIT01.TIF: 22/32
loaded DEM NAC_DTM_REINER5.TIF: 23/32
loaded DEM NAC_DTM_RILLERDGE.TIF: 24/32
loaded DEM NAC_DTM_MRINGENII4.TIF: 25/32
loaded DEM NAC_DTM_TYCHOPK05.TIF: 26/32
loaded DEM NAC_DTM_THEOPHILUS2.TIF: 27/32
loaded DEM NAC_DTM_FRSHCRATER16.TIF: 28/32
loaded DEM NAC_DTM_TYCHOPK.TIF: 29/32
loaded DEM NAC_DTM_NECTRIMII.TIF: 30/32
loaded DEM NAC_DTM_LASELMASIF4.TIF: 31/32
Loaded all DEMs in 44 seconds
#+end_example
: torch.Size([19775, 2, 256, 256])
:END:
#+RESULTS:

* SSIM

All credit to [[https://medium.com/srm-mic/all-about-structural-similarity-index-ssim-theory-code-in-pytorch-6551b455541e][Pranjal Datta]]

#+begin_src jupyter-python
def gaussian(window_size, sigma):
    """
    Generates a list of Tensor values drawn from a gaussian distribution with standard
    diviation = sigma and sum of all elements = 1.

    Length of list = window_size
    """
    gauss =  torch.Tensor([math.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])
    return gauss/gauss.sum()
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def create_window(window_size, channel=1):

    # Generate an 1D tensor containing values sampled from a gaussian distribution
    _1d_window = gaussian(window_size=window_size, sigma=1.5).unsqueeze(1)

    # Converting to 2D
    _2d_window = _1d_window.mm(_1d_window.t()).float().unsqueeze(0).unsqueeze(0)

    window = torch.Tensor(_2d_window.expand(channel, 1, window_size, window_size).contiguous())

    return window
#+end_src

#+RESULTS:

#+begin_src jupyter-python

def ssim(img1, img2, val_range, window_size=11, window=None, size_average=True, full=False):

    L = val_range # L is the dynamic range of the pixel values (255 for 8-bit grayscale images),

    pad = window_size // 2

    try:
        _, channels, height, width = img1.size()
    except:
        channels, height, width = img1.size()

    # if window is not provided, init one
    if window is None:
        real_size = min(window_size, height, width) # window should be atleast 11x11
        window = create_window(real_size, channel=channels).to(img1.device)

    # calculating the mu parameter (locally) for both images using a gaussian filter
    # calculates the luminosity params
    mu1 = F.conv2d(img1, window, padding=pad, groups=channels)
    mu2 = F.conv2d(img2, window, padding=pad, groups=channels)

    mu1_sq = mu1 ** 2
    mu2_sq = mu2 ** 2
    mu12 = mu1 * mu2

    # now we calculate the sigma square parameter
    # Sigma deals with the contrast component
    sigma1_sq = F.conv2d(img1 * img1, window, padding=pad, groups=channels) - mu1_sq
    sigma2_sq = F.conv2d(img2 * img2, window, padding=pad, groups=channels) - mu2_sq
    sigma12 =  F.conv2d(img1 * img2, window, padding=pad, groups=channels) - mu12

    # Some constants for stability
    C1 = (0.01 ) ** 2  # NOTE: Removed L from here (ref PT implementation)
    C2 = (0.03 ) ** 2

    contrast_metric = (2.0 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)
    contrast_metric = torch.mean(contrast_metric)

    numerator1 = 2 * mu12 + C1
    numerator2 = 2 * sigma12 + C2
    denominator1 = mu1_sq + mu2_sq + C1
    denominator2 = sigma1_sq + sigma2_sq + C2

    ssim_score = (numerator1 * numerator2) / (denominator1 * denominator2)

    if size_average:
        ret = ssim_score.mean()
    else:
        ret = ssim_score.mean(1).mean(1).mean(1)

    if full:
        return ret, contrast_metric

    return ret
#+end_src


#+RESULTS:

* Metrics

#+begin_src jupyter-python
checkpoint_path = "../slope_out/saved_models/gen_00000500.pt"

with torch.no_grad():
    netG = GSlope(config, config["cuda"])
    netG.load_state_dict(torch.load(checkpoint_path))

    if config["cuda"]:
        netG = netG.cuda()
#+end_src

#+RESULTS:


#+begin_src jupyter-python
# bboxes = torch.tensor([(74, 74, 182, 182)], dtype=torch.int64)
bboxes = torch.tensor([(0, 80, 256, 160)], dtype=torch.int64)

size = len(tiled)
SDD = np.zeros(size)
MAE = np.zeros(size)
RMSE = np.zeros(size)
SSIM = np.zeros(size)

for i, tile in tqdm(enumerate(tiled), total=len(tiled)):

    x, mask = mask_image(tile, bboxes, config, train=False)

    if config['cuda']:
        x = x.cuda()
        mask = mask.cuda()

    with torch.no_grad():
        x1, x2 = netG(x, mask)

    gt = tile[0, 74:182, 74:182]
    infill = x2[:, 0, 74:182, 74:182]
    gt = gt.unsqueeze(0)
    gt = gt.cuda()

    pdn_gt = partial_dn(gt)
    pdn_infill = partial_dn(infill)

    # SSIM needs data in range 0-1
    if pdn_infill.max() > pdn_gt.max():
        max_ = pdn_infill.max()
    else:
        max_ = pdn_gt.max()

    if pdn_infill.min() > pdn_gt.min():
        min_ = pdn_infill.min()
    else:
        min_ = pdn_gt.min()

    range_ = abs(max_ - min_)

    SSIM[i] = ssim(pdn_gt, pdn_infill, range_)

    # Other data needs data in denormalised range

    dem_min, dem_max = min_max[i]

    gt = denormalize(gt, dem_max, dem_min)
    infill = denormalize(infill, dem_max, dem_min)

    N = gt.size

    SDD[i] = np.abs(np.std(gt)) - np.abs(np.std(infill))

    MAE[i] = (1/N) * np.sum(np.abs(gt - infill))

    RMSE[i] = np.sqrt((1/N) * np.sum(np.square(gt - infill)))

#+end_src

#+RESULTS:
: 100% 19775/19775 [03:35<00:00, 91.87it/s]
:

#+begin_src jupyter-python
SDD_a = np.average(SDD)
MAE_a = np.average(MAE)
RMSE_a = np.average(RMSE)
SSIM_a = np.average(SSIM)

print(f'SDD: {SDD_a:.2f}, MAE:{MAE_a:.2f}, RMSE:{RMSE_a:.2f}, SSIM:{SSIM_a:.2f}')
#+end_src

#+RESULTS:
: SDD: 0.26, MAE:1.90, RMSE:2.66, SSIM:0.94
