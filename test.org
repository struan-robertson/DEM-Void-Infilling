#+title: Test
#+property: header-args :session test

Load a pre-trained model and generate some GeoTiffs with it

* Imports
#+begin_src jupyter-python
import os
import random
import toml

import numpy as np
from numpy.lib.stride_tricks import sliding_window_view
from osgeo import gdal

import matplotlib as mpl
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torchvision.transforms as transforms

from networks import Generator
from tools import random_bbox, mask_image
from blend import blend_images
#+End_src

#+RESULTS:

* Settings

#+begin_src jupyter-python
with open('config.toml', 'r') as file:
    config = toml.load(file)

# Test specific settings
config['cuda'] = False
config['dataset_name'] = "../datac/NAC_DTM_APENNINE01.TIF"
config['seed'] = 1433
#+end_src

#+RESULTS:

* Tile Dataset

#+begin_src jupyter-python
def normalise(arr):
    normalized = (arr - arr.min()) / (arr.max() - arr.min())

    normalized = 2*normalized - 1

    return normalized

def partial_norm(arr):
    normalized = (arr - arr.min()) / (arr.max() - arr.min())

    normalized = normalized - 1

    return normalized

#+end_src

#+RESULTS:

#+begin_src jupyter-python
def tile(dataset, kernel_size):

    dem = gdal.Open(dataset)

    crs = dem.GetProjection()
    geo_transform = dem.GetGeoTransform()

    image = dem.ReadAsArray()

    img_height, img_width = image.shape
    tile_height, tile_width = kernel_size

    # If cant divide perfectly
    if (img_height % tile_height != 0 or img_width % tile_width != 0):
        new_height = img_height - (img_height % tile_height)
        new_width = img_width - (img_width % tile_width)

        image = image[:new_height, :new_width]

    tiles_high = img_height // tile_height
    tiles_wide = img_width // tile_width

    tiled_array = image.reshape(tiles_high,
                                tile_height,
                                tiles_wide,
                                tile_width )

    tiled_array = tiled_array.swapaxes(1, 2)

    tiled_array = tiled_array.reshape(tiles_high * tiles_wide, tile_height, tile_width)

    # GC should get this, but just to be safe
    dem = None

    min_max = []
    for arr in tiled_array:
        min_max.append((arr.min(), arr.max()))

    vectorized_normalise = np.vectorize(normalise, signature='(n,m)->(n,m)')
    vectorized_partial_norm = np.vectorize(partial_norm, signature='(n,m)->(n,m)')

    tiled_array = vectorized_normalise(tiled_array)

    # Slope
    cellsize = geo_transform[1]
    px, py = np.gradient(tiled_array, cellsize, axis=(1,2))
    slope = np.arctan(np.sqrt(px ** 2 + py ** 2))
    slope = vectorized_partial_norm(slope)

    # # RDLS
    # windowed = sliding_window_view(tiled_array, (3,3), axis=(1,2))
    # rdls = np.ptp(windowed, axis=(3,4))
    # rdls = np.pad(rdls, ((0,0), (1,1), (1,1)), mode='constant', constant_values=0)
    # rdls = vectorized_normalise(rdls)

    # all = np.stack((tiled_array, slope), axis=3)

    tiled_array = np.expand_dims(tiled_array, axis=3)
    tiled_array = np.transpose(tiled_array, (0, 3, 1, 2))

    # H,W,C to C,H,W
    return torch.from_numpy(tiled_array), min_max, crs, geo_transform

#+end_src

#+RESULTS:

* Image Transformations
#+begin_src jupyter-python

# Return data from -1<->1 normalisation to original state
def denormalize(tensor, max, min):
    arr = tensor.cpu().detach().numpy()

    arr = arr.squeeze()

    arr = (arr * 0.5) + 0.5
    arr = (arr * (max - min)) + min

    return arr

# Return data from -1<->1 normalisation to 0<->1 normalisation
# Used as poisson blending requires the DEM data to be 0<->1 but the inpainted DEM is returened -1<->1
def partial_dn(tensor):

    arr = tensor.cpu().detach().numpy()

    arr = arr.squeeze()

    arr = (arr * 0.5) + 0.5

    return arr

#+end_src

#+RESULTS:

* Setup
** Seed

Can probably get rid of this, no training is happening
#+begin_src jupyter-python
if config["seed"]:
    seed = config["seed"]
    random.seed(seed)
    torch.manual_seed(seed)
#+end_src

#+RESULTS:

** Get Tile
#+begin_src jupyter-python
tiled, min_max, crs, geo_transform = tile(config["dataset_name"], (256, 256))

tiled.shape
#+end_src

#+RESULTS:
: torch.Size([484, 1, 256, 256])
* Infill

Not the most efficient way of doing things but since individual DEM files are (probably) much larger than the tiles the network is trained on.
Also a lot of data (annoyingly) seems to be basic slopes that arent very interesting.
 - There maybe is something to be said for trying to find high res (5m) DEMs with consistently complex terrain.

** Workflow
 - Manually iterate through tiles until an interesting tile is found
 - Generate infilled DEM
 - If it is either really good or really shit save to file as it will be good for the report.

** Select Tile

#+begin_src jupyter-python
def display(image):

    if isinstance(image, torch.Tensor):
        image = image.cpu().detach().numpy()
        image = image.squeeze()
        # image = np.transpose(image, (1,2,0))

    # plt.figure(figsize=(15,4))
    # plt.subplot(1,1,1)
    plt.imshow(image, cmap='terrain')
    plt.title("DEM")
    plt.colorbar()
    # plt.subplot(1,2,2)
    # plt.imshow(image[:,:,1], cmap='viridis')
    # plt.title("Slope")
    # plt.colorbar()
#+end_src

#+RESULTS:

#+begin_src jupyter-python
print(len(tiled))
#+end_src

#+RESULTS:
: 484

#+begin_src jupyter-python
tile_n = 100

dem = tiled[tile_n]
dem_min, dem_max = min_max[tile_n]

display(denormalize(dem, dem_max, dem_min))
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/412d3a37a27f80042580bb1aa3df1be1e9d97a57.png]]

** Infill
#+begin_src jupyter-python

#### Transforms

#### Infill void

# Different from normal bbox
# (y1, x1, y2, x2)
bboxes = torch.tensor([(0, 64, 256, 192)], dtype=torch.int64)
x, mask = mask_image(dem, bboxes, config, train=False)

checkpoint_path = "../out_backup/saved_models/gen_00000152.pt"

inpainted_result = None
x2 = None

with torch.no_grad():

    netG = Generator(config, config["cuda"])
    netG.load_state_dict(torch.load(checkpoint_path))
    x1, x2 = netG(x, mask)
    inpainted_result = x2 * mask + x * (1. - mask)

#### De-normalize
# inpainted_result_dn = denormalize(inpainted_result, img_max, img_min)
# ground_truth_dn = denormalize(ground_truth, img_max, img_min)


plt.figure(figsize=(15,15))
plt.subplot(1,2,1)
display(inpainted_result)
plt.subplot(1,2,2)
plt.imshow(np.squeeze(mask))
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/e9e89bfb32b944376d622e80bb78184c4999f8df.png]]
: <matplotlib.image.AxesImage at 0x7f66b5b33070>
[[file:./.ob-jupyter/9ac774bdac94730ea415e02aa636740c51c80ad6.png]]
:END:

** Poisson Blending
#+begin_src jupyter-python
mask = mask.cpu().detach().numpy()
mask = np.squeeze(mask)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
infill = partial_dn(x2)
gt = partial_dn(dem)

infill = np.pad(infill, ((1,1), (0,0)), mode='constant', constant_values=0)
gt = np.pad(gt, ((1,1), (0,0)), mode='constant', constant_values=0)
mask = np.pad(mask, ((1,1), (0,0)), mode='constant', constant_values=0)

blended = blend_images(infill, gt, mask)

blended = (blended * (dem_max - dem_min)) + dem_min

ground_truth = denormalize(dem, dem_max, dem_min)
inpainted_full = denormalize(x2, dem_max, dem_min)
combined = denormalize(inpainted_result, dem_max, dem_min)

plt.figure(figsize=(15,15))
plt.subplot(1,4,1)
plt.imshow(ground_truth, cmap='terrain')
plt.title("Ground Truth")
plt.subplot(1,4,2)
plt.imshow(inpainted_full, cmap='terrain')
plt.title("Inpainted Result")
plt.subplot(1,4,3)
plt.imshow(combined, cmap='terrain')
plt.title("Combined")
plt.subplot(1,4,4)
plt.imshow(blended, cmap='terrain')
plt.title("Poisson Blended")
plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/0015e6b2e6982ed1159b568573ca2ceaf8cba531.png]]



** Save

#+begin_src jupyter-python
if not os.path.exists('test_results'):
    os.makedirs('test_results')

def write_geotiff(filename, arr):

    driver = gdal.GetDriverByName("GTiff")
    out_ds = driver.Create(filename, arr.shape[1], arr.shape[0], 1, gdal.GDT_Float32)
    out_ds.SetProjection(crs)

    # Get properties from input DEM
    upper_left, pixel_width, rotation, upper_right, rotation, pixel_height = geo_transform

    # Calculate tile coordinates
    upper_left += (tile_n + 1) * 256
    upper_right += (tile_n + 1) * 256

    # Set Geo-transform
    out_ds.SetGeoTransform((upper_left, pixel_width, rotation, upper_right, rotation, pixel_height))

    band = out_ds.GetRasterBand(1)
    band.WriteArray(arr)
    band.FlushCache()
    band.ComputeStatistics(False)

write_geotiff(f'test_results/{tile_n}_inpaint_poisson.tif', blended)
write_geotiff(f'test_results/{tile_n}_inpaint.tif', combined)
write_geotiff(f'test_results/{tile_n}_gt.tif', ground_truth)
#+end_src

#+RESULTS:
