#+title: Test
#+property: header-args :session test

Load a pre-trained model and generate some GeoTiffs with it

* Imports
#+begin_src jupyter-python
import os
import random

import numpy as np
from numpy.lib.stride_tricks import sliding_window_view
from osgeo import gdal

import matplotlib as mpl
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torchvision.transforms as transforms

from networks import Generator
from tools import random_bbox, mask_image
from blend import blend_images

import toml
from ipdb import set_trace
#+End_src

#+RESULTS:

* Settings

#+begin_src jupyter-python
with open('config.toml', 'r') as file:
    config = toml.load(file)

# Test specific settings
config['dataset_name'] = "../Testing Data/NPC_cubic.tif"
config['seed'] = 6747
#+end_src

#+RESULTS:

* Tile Dataset

#+begin_src jupyter-python
def normalise(arr):
    normalized = (arr - arr.min()) / (arr.max() - arr.min())

    normalized = 2*normalized - 1

    return normalized
#+end_src

#+RESULTS:

#+begin_src jupyter-python
def tile(dataset, kernel_size):

    dem = gdal.Open(dataset)

    crs = dem.GetProjection()
    geo_transform = dem.GetGeoTransform()

    # image = np.array(dem.ReadAsArray())
    image = dem.ReadAsArray()

    img_height, img_width = image.shape
    tile_height, tile_width = kernel_size

    # If cant divide perfectly
    if (img_height % tile_height != 0 or img_width % tile_width != 0):
        new_height = img_height - (img_height % tile_height)
        new_width = img_width - (img_width % tile_width)

        image = image[:new_height, :new_width]

    tiles_high = img_height // tile_height
    tiles_wide = img_width // tile_width

    tiled_array = image.reshape(tiles_high,
                                tile_height,
                                tiles_wide,
                                tile_width )

    tiled_array = tiled_array.swapaxes(1, 2)

    tiled_array = tiled_array.reshape(tiles_high * tiles_wide, tile_height, tile_width)

    # GC should get this, but just to be safe
    dem = None

    vectorized_normalise = np.vectorize(normalise, signature='(n,m)->(n,m)')

    tiled_array = vectorized_normalise(tiled_array)

    # Slope
    cellsize = geo_transform[1]
    px, py = np.gradient(tiled_array, cellsize, axis=(1,2))
    slope = np.arctan(np.sqrt(px ** 2 + py ** 2))
    slope = vectorized_normalise(slope)

    # RDLS
    windowed = sliding_window_view(tiled_array, (3,3), axis=(1,2))
    rdls = np.ptp(windowed, axis=(3,4))
    rdls = np.pad(rdls, ((0,0), (1,1), (1,1)), mode='constant', constant_values=0)
    rdls = vectorized_normalise(rdls)

    all = np.stack((tiled_array, slope, rdls), axis=3)

    # H,W,C to C,H,W
    all = np.transpose(all, (0,3,1,2))

    return torch.from_numpy(all), crs, geo_transform

#+end_src

#+RESULTS:

* Image Transformations
#+begin_src jupyter-python

# Return data from -1<->1 normalisation to original state
def denormalize(tensor, max, min):
    arr = tensor.cpu().detach().numpy()

    arr = np.transpose(arr, (1,2,0))

    arr = (arr * 0.5) + 0.5
    arr = (arr * (max - min)) + min

    return arr

# Return data from -1<->1 normalisation to 0<->1 normalisation
# Used as poisson blending requires the DEM data to be 0<->1 but the inpainted DEM is returened -1<->1
def partial_dn(tensor):

    arr = tensor.cpu().detach().numpy()

    arr = np.transpose(arr, (1,2,0))
    arr = (arr * 0.5) + 0.5

    return arr

#+end_src

#+RESULTS:

* Setup
** Seed

Can probably get rid of this, no training is happening
#+begin_src jupyter-python
if config["seed"]:
    seed = config["seed"]
    random.seed(seed)
    torch.manual_seed(seed)
#+end_src

#+RESULTS:

** Get Tile
#+begin_src jupyter-python
tiled, crs, geo_transform = tile(config["dataset_name"], (256, 256))

tiled.shape
#+end_src

#+RESULTS:
: torch.Size([49, 3, 256, 256])
* Infill

Not the most efficient way of doing things but since individual DEM files are (probably) much larger than the tiles the network is trained on.
Also a lot of data (annoyingly) seems to be basic slopes that arent very interesting.
 - There maybe is something to be said for trying to find high res (5m) DEMs with consistently complex terrain.

** Workflow
 - Manually iterate through tiles until an interesting tile is found
 - Generate infilled DEM
 - If it is either really good or really shit save to file as it will be good for the report.

** Select Tile

#+begin_src jupyter-python
print(len(tiled))
#+end_src

#+RESULTS:
: 49

#+begin_src jupyter-python
tile_n = 0

dem = tiled[tile_n]

image = dem.cpu().detach().numpy()
image = np.transpose(image, (1,2,0))

plt.figure(figsize=(15,4))
plt.subplot(1,3,1)
plt.imshow(image[:,:,0], cmap='terrain')
plt.title("DEM")
plt.colorbar()
plt.subplot(1,3,2)
plt.imshow(image[:,:,1], cmap='viridis')
plt.title("Slope")
plt.colorbar()
plt.subplot(1,3,3)
plt.imshow(image[:,:,2], cmap='viridis')
plt.title("RDLS")
plt.colorbar()
plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/127af3f3114f2c649889e43d637b651305e11c77.png]]

** Infill
#+begin_src jupyter-python

#### Transforms

dem_min = np.amin(dem)
dem_max = np.amax(dem)

transform = transforms.Compose(transforms_)
ground_truth = transform(dem)

#### Infill void

# Remember (start_x, start_y, size_x, size_y)
bboxes = torch.tensor([(64, 64, 128, 128)], dtype=torch.int64)
x, mask = mask_image(ground_truth, bboxes, config, train=False)

checkpoint_path = "out/saved_models/gen_00000100.pt"

inpainted_result = None
x2 = None

with torch.no_grad():

    netG = Generator(config, config["cuda"])
    netG.load_state_dict(torch.load(checkpoint_path))

    x1, x2 = netG(x, mask)
    inpainted_result = x2 * mask + x * (1. - mask)

#### De-normalize
inpainted_result_dn = denormalize(inpainted_result, img_max, img_min)
ground_truth_dn = denormalize(ground_truth, img_max, img_min)
#+end_src

#+RESULTS:
** Poisson Blending
#+begin_src jupyter-python
mask = mask.cpu().detach().numpy()
mask = np.squeeze(mask)

infill = partial_dn(x2)
gt = partial_dn(ground_truth)

blended = blend_images(infill, gt, mask)

blended = (blended * (img_max - img_min)) + img_min
#+end_src

#+RESULTS:

#+begin_src jupyter-python
plt.figure(figsize=(15,15))
plt.subplot(1,3,1)
plt.imshow(ground_truth_dn, cmap='terrain')
plt.title("Ground Truth")
plt.subplot(1,3,2)
plt.imshow(inpainted_result_dn, cmap='terrain')
plt.title("Inpainted Result")
plt.subplot(1,3,3)
plt.imshow(blended, cmap='terrain')
plt.title("Poisson Blended")
plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/5e8c9efb246996bb384d33cfeaab3c4d866ddb8f.png]]

** Save

#+begin_src jupyter-python
if not os.path.exists('test_results'):
    os.makedirs('test_results')

def write_geotiff(filename, arr):

    driver = gdal.GetDriverByName("GTiff")
    out_ds = driver.Create(filename, arr.shape[1], arr.shape[0], 1, gdal.GDT_Float32)
    out_ds.SetProjection(crs)

    # Get properties from input DEM
    upper_left, pixel_width, rotation, upper_right, rotation, pixel_height = geo_transform

    # Calculate tile coordinates
    upper_left += (tile_n + 1) * 256
    upper_right += (tile_n + 1) * 256

    # Set Geo-transform
    out_ds.SetGeoTransform((upper_left, pixel_width, rotation, upper_right, rotation, pixel_height))

    band = out_ds.GetRasterBand(1)
    band.WriteArray(arr)
    band.FlushCache()
    band.ComputeStatistics(False)

write_geotiff(f'test_results/{tile_n}_inpaint_poisson.tif', blended)
write_geotiff(f'test_results/{tile_n}_inpaint.tif', inpainted_result_dn)
write_geotiff(f'test_results/{tile_n}_gt.tif', ground_truth_dn)
#+end_src

#+RESULTS:
